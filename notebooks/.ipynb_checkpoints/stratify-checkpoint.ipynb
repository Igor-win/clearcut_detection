{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import imageio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gp\n",
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = '../data'\n",
    "IMAGES_PATH = 'images'\n",
    "MASKS_PATH = 'masks'\n",
    "INSTANCES_PATH = 'instance_masks'\n",
    "WIDHT , HEIGHT = 224, 224\n",
    "CHANNELS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_pathes(\n",
    "    datasets_path, images_path_name='images',\n",
    "    masks_path_name='masks', instances_path_name='instance_masks'):\n",
    "    \n",
    "    datasets = list(os.walk(datasets_path))[0][1]\n",
    "    data_pathes = []\n",
    "    for dataset in datasets:\n",
    "        data_pathes.append((\n",
    "            os.path.join(datasets_path, dataset, images_path_name),\n",
    "            os.path.join(datasets_path, dataset, masks_path_name),\n",
    "            os.path.join(datasets_path, dataset, instances_path_name)))\n",
    "    \n",
    "    return data_pathes\n",
    "\n",
    "\n",
    "def get_instances(instances_path):\n",
    "    return list(os.walk(instances_path))[0][1]\n",
    "\n",
    "\n",
    "def image2mask(image_path, image_type):\n",
    "    return imageio.imread('{}.{}'.format(image_path, image_type))\n",
    "\n",
    "\n",
    "def get_data(images_path, masks_path, instances, image_type='jpeg', mask_type='png'):\n",
    "    X = np.array([\n",
    "         image2mask(os.path.join(images_path, i), image_type)for i in instances])\n",
    "    y = np.array([\n",
    "        image2mask(os.path.join(masks_path, i), mask_type)for i in instances])\n",
    "    y = y.reshape([*y.shape, 1])\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "\n",
    "def get_area(instance_path):\n",
    "    return (gp.read_file(instance_path)['geometry'].area / 100).median()\n",
    "\n",
    "    \n",
    "def get_labels(distr):\n",
    "    res = np.full(distr.shape, 3)\n",
    "    res[distr < np.quantile(distr, 0.75)] = 2\n",
    "    res[distr < np.quantile(distr, 0.5)] = 1\n",
    "    res[distr < np.quantile(distr, 0.25)] = 0\n",
    "    return res\n",
    "\n",
    "\n",
    "def stratify(datasets_path, test_size=0.2):\n",
    "    datasets = get_data_pathes(datasets_path)\n",
    "    images_path, masks_path, instances_path = datasets[0]\n",
    "    instances = list(os.walk(instances_path))[0][1]\n",
    "    X, _ = get_data(images_path, masks_path, instances)\n",
    "    areas = np.array([\n",
    "        get_area(os.path.join(instances_path, i, i + '.geojson')) for i in instances])\n",
    "    labels = get_labels(areas)\n",
    "\n",
    "    sss = StratifiedShuffleSplit(\n",
    "        n_splits=len(datasets), test_size=test_size, random_state=42)\n",
    "    \n",
    "    return sss.split(X, labels)\n",
    "\n",
    "\n",
    "def build_generator(datasets_path):\n",
    "    stratified_ix = stratify(datasets_path)\n",
    "    datasets = get_data_pathes(datasets_path)\n",
    "    for images_path, masks_path, instances_path in datasets:\n",
    "        instances = list(os.walk(instances_path))[0][1]\n",
    "        X, y = get_data(images_path, masks_path, instances)\n",
    "        for train_ix, test_ix in stratify(DATA):\n",
    "            X_train, X_test = X[train_ix], X[test_ix]\n",
    "            y_train, y_test = y[train_ix], y[test_ix]\n",
    "            \n",
    "        yield X_train\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(196, 224, 224, 3)\n",
      "(196, 224, 224, 1)\n",
      "(49, 224, 224, 3)\n",
      "(49, 224, 224, 1)\n"
     ]
    }
   ],
   "source": [
    "images_path, masks_path, instances_path = get_data_pathes(DATA)[0]\n",
    "instances = get_instances(instances_path)\n",
    "X, y = get_data(images_path, masks_path, instances)\n",
    "for train_ix, test_ix in stratify(DATA):\n",
    "    X_train, X_test = X[train_ix], X[test_ix]\n",
    "    y_train, y_test = y[train_ix], y[test_ix]\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_batch_generator(filenames, img_data_dir, shuffle, img_type, batch_size=32, seed=10):\n",
    "\n",
    "    while True:\n",
    "        if shuffle:\n",
    "            filenames = sklearn.utils.shuffle(filenames)\n",
    "\n",
    "        for start in range(0, len(filenames), batch_size):\n",
    "            images = []\n",
    "            masks = []\n",
    "            end = min(start + batch_size, len(filenames))\n",
    "            train_batch = filenames[start:end]\n",
    "\n",
    "            for ind, filename in train_batch.iterrows():\n",
    "                img_path = os.path.join(img_data_dir, \"images\", filename['image_name'], '{}'.format(img_type))\n",
    "                mask_path = os.path.join(img_data_dir, \"masks\", filename['image_name'], '{}'.format(img_type))\n",
    "\n",
    "                img = img_to_array(load_img(os.path.join(img_path, filename['name']), grayscale=False))\n",
    "                mask = img_to_array(load_img(os.path.join(mask_path, filename['name']), grayscale=False))\n",
    "\n",
    "                images.append(img)\n",
    "                masks.append(mask)\n",
    "\n",
    "            images = np.array(images, np.float32)\n",
    "            masks = np.array(masks, np.float32)\n",
    "\n",
    "            yield images, masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(args.train_df)\n",
    "val_df = pd.read_csv(args.val_df)\n",
    "\n",
    "train_generator = build_batch_generator(\n",
    "    filenames=train_df,\n",
    "    img_data_dir=args.dataset_path,\n",
    "    shuffle=True,\n",
    "    img_type=\"png\",\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "val_generator = build_batch_generator(\n",
    "    filenames=val_df,\n",
    "    img_data_dir=args.dataset_path,\n",
    "    shuffle=True,\n",
    "    img_type=\"png\",\n",
    "    batch_size=32\n",
    ")\n",
    "model.fit_generator(\n",
    "    ThreadsafeIter(train_generator),\n",
    "    steps_per_epoch=len(train_df) / args.batch_size + 1,\n",
    "    epochs=args.epochs,\n",
    "    validation_data=ThreadsafeIter(val_generator),\n",
    "    validation_steps=len(val_df) / args.batch_size + 1,\n",
    "    callbacks=callbacks,\n",
    "    max_queue_size=50,\n",
    "    workers=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
