{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import imageio\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gp\n",
    "\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data'\n",
    "IMAGES_FOLDER = 'images'\n",
    "MASKS_FOLDER = 'masks'\n",
    "INSTANCES_FOLDER = 'instance_masks'\n",
    "IMAGE_TYPE = 'tiff'\n",
    "MASK_TYPE = 'png'\n",
    "INSTANCE_TYPE = 'geojson'\n",
    "CHANNELS = ['rgb', 'ndvi', 'ndvi_color', 'b2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_info(data_path=DATA_PATH):  \n",
    "    \n",
    "    dataset = get_folders(data_path)[0]\n",
    "    _, _, insatnces_path = get_data_pathes(data_path)\n",
    "    instances = get_folders(insatnces_path)\n",
    "    \n",
    "    cols = ['date', 'name', 'ix', 'iy']\n",
    "    data_info = pd.DataFrame(columns=cols)\n",
    "    for instance in instances:\n",
    "        name_parts = split_fullname(instance)\n",
    "        data_info = data_info.append(\n",
    "            pd.DataFrame({\n",
    "                'date': name_parts[0],\n",
    "                'name': name_parts[1],\n",
    "                'ix': name_parts[3],\n",
    "                'iy': name_parts[4]\n",
    "            }, index=[0]),\n",
    "            sort=True, ignore_index=True\n",
    "        )\n",
    "        \n",
    "    return data_info\n",
    "\n",
    "\n",
    "def get_data_pathes(\n",
    "    data_path=DATA_PATH, images_folder=IMAGES_FOLDER,\n",
    "    masks_folder=MASKS_FOLDER, instances_folder=INSTANCES_FOLDER\n",
    "):\n",
    "    \n",
    "    dataset = get_folders(data_path)[0]\n",
    "    \n",
    "    images_path = os.path.join(data_path, dataset, images_folder)\n",
    "    masks_path = os.path.join(data_path, dataset, masks_folder)\n",
    "    insatnces_path = os.path.join(data_path, dataset, instances_folder)\n",
    "    \n",
    "    return images_path, masks_path, insatnces_path\n",
    "    \n",
    "    \n",
    "def get_folders(path):\n",
    "    return list(os.walk(path))[0][1]\n",
    "\n",
    "\n",
    "def split_fullname(fullname):\n",
    "    return fullname.split('_')\n",
    "\n",
    "\n",
    "def get_fullname(*name_parts):\n",
    "    return '_'.join(tuple(map(str, name_parts)))\n",
    "\n",
    "\n",
    "def get_filepath(*path_parts, file_type):\n",
    "    return '{}.{}'.format(join_pathes(*path_parts), file_type)\n",
    "\n",
    "\n",
    "def join_pathes(*pathes):\n",
    "    return os.path.join(*pathes)\n",
    "\n",
    "\n",
    "def stratify(\n",
    "    data_info, data_path=DATA_PATH, \n",
    "    test_size=0.2, random_state=42,\n",
    "    channel=CHANNELS[0], instance_type=INSTANCE_TYPE,\n",
    "    instances_folder=INSTANCES_FOLDER\n",
    "):\n",
    "    \n",
    "    X, _ = get_data(data_info)\n",
    "    areas = []\n",
    "    for _, row in data_info.iterrows():\n",
    "        instance_name = get_fullname(row['date'], row['name'], channel, row['ix'], row['iy'])\n",
    "        instance_path = get_filepath(\n",
    "            data_path,\n",
    "            get_fullname(row['date'], row['name'], channel),\n",
    "            instances_folder,\n",
    "            instance_name,\n",
    "            instance_name,\n",
    "            file_type=instance_type\n",
    "        )\n",
    "        areas.append(get_area(instance_path))\n",
    "                     \n",
    "    labels = get_labels(np.array(areas))\n",
    "\n",
    "    sss = StratifiedShuffleSplit(\n",
    "        n_splits=1,\n",
    "        test_size=test_size,\n",
    "        random_state=random_state\n",
    "    )\n",
    "\n",
    "    return sss.split(X, labels)\n",
    "\n",
    "\n",
    "def get_data(\n",
    "    data_info, channel=CHANNELS[0], data_path=DATA_PATH,\n",
    "    image_folder=IMAGES_FOLDER, mask_folder=MASKS_FOLDER,\n",
    "    image_type=IMAGE_TYPE, mask_type=MASK_TYPE\n",
    "):\n",
    "    \n",
    "    x = []\n",
    "    y = []\n",
    "    for _, row in data_info.iterrows():\n",
    "        dataset = get_fullname(row['date'], row['name'], channel)\n",
    "        filename = get_fullname(row['date'], row['name'], channel, row['ix'], row['iy'])\n",
    "        \n",
    "        image_path = get_filepath(\n",
    "            data_path,\n",
    "            dataset,\n",
    "            image_folder,\n",
    "            filename,\n",
    "            file_type=image_type\n",
    "        )\n",
    "        mask_path = get_filepath(\n",
    "            data_path,\n",
    "            dataset,\n",
    "            mask_folder,\n",
    "            filename,\n",
    "            file_type=mask_type\n",
    "        )\n",
    "        \n",
    "        x.append(read_tensor(image_path))\n",
    "        y.append(read_tensor(mask_path))\n",
    "        \n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    y = y.reshape([*y.shape, 1])\n",
    "\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def read_tensor(filepath):\n",
    "    return imageio.imread(filepath)\n",
    "\n",
    "\n",
    "def get_area(instance_path):\n",
    "    return (gp.read_file(instance_path)['geometry'].area / 100).median()\n",
    "\n",
    "\n",
    "def get_labels(distr):\n",
    "    res = np.full(distr.shape, 3)\n",
    "    res[distr < np.quantile(distr, 0.75)] = 2\n",
    "    res[distr < np.quantile(distr, 0.5)] = 1\n",
    "    res[distr < np.quantile(distr, 0.25)] = 0\n",
    "    return res\n",
    "\n",
    "\n",
    "def stratified_split(data_info, data_path=DATA_PATH, \n",
    "                     test_size=0.2, random_state=42,\n",
    "                     channel=CHANNELS[0], instance_type=INSTANCE_TYPE,\n",
    "                     instances_folder=INSTANCES_FOLDER):\n",
    "    \n",
    "    stratified_indexes = stratify(\n",
    "        data_info, data_path=DATA_PATH, \n",
    "        test_size=0.2, random_state=42,\n",
    "        channel=CHANNELS[0], instance_type=INSTANCE_TYPE,\n",
    "        instances_folder=INSTANCES_FOLDER\n",
    "    )\n",
    "    \n",
    "    for train_ix, test_ix in stratified_indexes:\n",
    "        train_df = data_info.iloc[train_ix]\n",
    "        test_df = data_info.iloc[test_ix]\n",
    "    \n",
    "    train_df.to_csv(\n",
    "        get_filepath(data_path, 'train_df', file_type='csv'),\n",
    "        index=False\n",
    "    )\n",
    "    test_df.to_csv(\n",
    "        get_filepath(data_path, 'test_df', file_type='csv'),\n",
    "        index=False\n",
    "    )\n",
    "    \n",
    "    return train_df, test_df\n",
    "\n",
    "\n",
    "def get_input_pair(data_info_row, channels=CHANNELS, data_path=DATA_PATH,\n",
    "              image_folder=IMAGES_FOLDER, mask_folder=MASKS_FOLDER,\n",
    "              image_type=IMAGE_TYPE, mask_type=MASK_TYPE):\n",
    "    \n",
    "    image_tensors = []\n",
    "    for channel in channels:\n",
    "        dataset = get_fullname(\n",
    "            data_info_row['date'],\n",
    "            data_info_row['name'],\n",
    "            channel\n",
    "        )\n",
    "        filename = get_fullname(\n",
    "            data_info_row['date'], data_info_row['name'],\n",
    "            channel, data_info_row['ix'], data_info_row['iy']\n",
    "        )\n",
    "        image_path = get_filepath(\n",
    "            data_path,\n",
    "            dataset,\n",
    "            image_folder,\n",
    "            filename,\n",
    "            file_type=image_type\n",
    "        )\n",
    "        \n",
    "        image_tensor = read_tensor(image_path)\n",
    "        if image_tensor.ndim == 2:\n",
    "            image_tensor = image_tensor.reshape(*image_tensor.shape, 1)\n",
    "        \n",
    "        image_tensors.append(image_tensor)\n",
    "        \n",
    "    mask_path = get_filepath(\n",
    "        data_path,\n",
    "        dataset,\n",
    "        mask_folder,\n",
    "        filename,\n",
    "        file_type=mask_type\n",
    "    )\n",
    "\n",
    "    image = transforms.ToTensor()(np.concatenate(image_tensors, axis=2))\n",
    "    mask = transforms.ToTensor()(read_tensor(mask_path))\n",
    "\n",
    "    return {'features': image, 'targets': mask}\n",
    "\n",
    "\n",
    "def create_loaders(train_df, val_df):\n",
    "    train_loader = UtilsFactory.create_loader(\n",
    "        train_df,\n",
    "        open_fn=get_image,\n",
    "        batch_size=args.batch_size,\n",
    "        num_workers=args.num_workers,\n",
    "        shuffle=True)\n",
    "\n",
    "    valid_loader = UtilsFactory.create_loader(\n",
    "        val_df,\n",
    "        open_fn=get_image,\n",
    "        batch_size=args.batch_size,\n",
    "        num_workers=args.num_workers,\n",
    "        shuffle=True)\n",
    "\n",
    "    loaders = collections.OrderedDict()\n",
    "    loaders[\"train\"] = train_loader\n",
    "    loaders[\"valid\"] = valid_loader\n",
    "    \n",
    "    return loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ix</th>\n",
       "      <th>iy</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20160103</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>66979721-be1b-4451-84e0-4a573236defd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20160103</td>\n",
       "      <td>26</td>\n",
       "      <td>13</td>\n",
       "      <td>66979721-be1b-4451-84e0-4a573236defd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20160103</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>66979721-be1b-4451-84e0-4a573236defd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20160103</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>66979721-be1b-4451-84e0-4a573236defd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20160103</td>\n",
       "      <td>30</td>\n",
       "      <td>16</td>\n",
       "      <td>66979721-be1b-4451-84e0-4a573236defd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       date  ix  iy                                  name\n",
       "0  20160103  20  20  66979721-be1b-4451-84e0-4a573236defd\n",
       "1  20160103  26  13  66979721-be1b-4451-84e0-4a573236defd\n",
       "2  20160103  12  22  66979721-be1b-4451-84e0-4a573236defd\n",
       "3  20160103  16   5  66979721-be1b-4451-84e0-4a573236defd\n",
       "4  20160103  30  16  66979721-be1b-4451-84e0-4a573236defd"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_info = get_data_info()\n",
    "data_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(245, 224, 224, 3)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = get_data(data_info)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = stratified_split(data_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.to_dict('records')\n",
    "test_df = test_df.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair = get_input_pair(train_df[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9, 224, 224])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair['features'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
